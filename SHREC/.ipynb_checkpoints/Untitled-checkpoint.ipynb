{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Joseph\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GlobalAveragePool2D' from 'tensorflow.keras.layers' (C:\\Users\\Joseph\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\api\\_v2\\keras\\layers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-65f0d28875b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalMaxPool2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalAveragePool2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpatialDropout2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexpand_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'GlobalAveragePool2D' from 'tensorflow.keras.layers' (C:\\Users\\Joseph\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\api\\_v2\\keras\\layers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import gc\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras import backend as K\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy\n",
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, GlobalMaxPool2D, GlobalAveragePooling2D, BatchNormalization, SpatialDropout2D, LeakyReLU, Conv2D, AveragePooling2D, Dropout, Flatten, Lambda, Dense, MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.frame_l = 32 # the length of frames\n",
    "        self.joint_n = 12 # the number of joints\n",
    "        self.joint_n = 22#43#22 # the number of joints\n",
    "        self.joint_d = 3 # the dimension of joints\n",
    "        self.clc_coarse = 14#28#14 # the number of coarse class\n",
    "        self.clc_fine = 28 # the number of fine-grained class\n",
    "        self.feat_d = 231\n",
    "        self.filters = 16#32#16\n",
    "        self.data_dir = 'E:\\Skelnet2D\\data\\SHREC\\\\'\n",
    "C = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "dropout_probability = 0.1\n",
    "duration = 32\n",
    "n_classes = 14\n",
    "n_channels = 22  # usually  n_channels = 2 * n_joints  or  n_channels = 3 * n_joints\n",
    "filters = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c2D(x,filters,kernel):\n",
    "    x = Conv2D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = SpatialDropout2D(dropout_probability)(x)\n",
    "    return x\n",
    "\n",
    "def block(x,filters):\n",
    "    x = c2D(x,filters,3)\n",
    "    x = c2D(x,filters,3)\n",
    "    return x\n",
    "    \n",
    "def d2D(x,filters):\n",
    "    x = Dense(filters,use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_classes, duration, n_channels, dropout_probability=0.2):\n",
    "    model_input = Input(shape=(duration, n_channels,3))\n",
    "    \n",
    "    high = c2D(model_input, filters*2,7)\n",
    "    high = AveragePooling2D((2, 2), padding='same')(high)\n",
    "    high = c2D(high, filters*2,7)\n",
    "    high = AveragePooling2D((2, 2), padding='same')(high)\n",
    "    high = c2D(high, filters*2,7)\n",
    "    high = MaxPooling2D((2, 2), padding='same')(high)\n",
    "    \n",
    "    low = c2D(model_input, filters*2,3)\n",
    "    low = AveragePooling2D((2, 2), padding='same')(low)\n",
    "    low = c2D(low, filters*2,3)\n",
    "    low = AveragePooling2D((2, 2), padding='same')(low)\n",
    "    low = c2D(low, filters*2,3)\n",
    "    low = AveragePooling2D((2, 2), padding='same')(low)\n",
    "    \n",
    "    ap_residual = AveragePooling2D((2, 2), padding='same', input_shape=(32,n_channels, 1))(model_input)\n",
    "    ap_residual = AveragePooling2D((2, 2), padding='same')(ap_residual)\n",
    "    ap_residual = AveragePooling2D((2, 2), padding='same')(ap_residual)\n",
    "    \n",
    "    channel_output = concatenate([low,high,ap_residual])\n",
    "    features = block(channel_output,filters*2)\n",
    "    features = block(channel_output,filters*2)\n",
    "    features = GlobalAveragePooling2D()(features)\n",
    "    features = d2D(features,128)\n",
    "    features = Dropout(dropout_probability)(features)\n",
    "    features = d2D(features,128)\n",
    "    features = Dropout(dropout_probability)(features)\n",
    "    model_output = Dense(units=n_classes, activation='softmax')(features)\n",
    "        \n",
    "    model = Model(inputs=[model_input], outputs=[model_output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(n_classes=n_classes, duration=duration, n_channels=n_channels, dropout_probability=dropout_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pickle.load(open(C.data_dir+\"train.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(C.data_dir+\"test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = []\n",
    "X_1 = []\n",
    "Y = []\n",
    "for i in tqdm(range(len(Train['pose']))): \n",
    "    p = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range(p)\n",
    "    \n",
    "    label = np.zeros(C.clc_coarse)\n",
    "    label[Train['coarse_label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_0.append(M)\n",
    "    X_1.append(p)\n",
    "    Y.append(label)\n",
    "\n",
    "X_0 = np.stack(X_0)  \n",
    "X_1 = np.stack(X_1) \n",
    "Y = np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_0 = []\n",
    "X_test_1 = []\n",
    "Y_test = []\n",
    "for i in tqdm(range(len(Test['pose']))): \n",
    "    p = np.copy(Test['pose'][i]).reshape([-1,22,3])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range(p)\n",
    "    \n",
    "    label = np.zeros(C.clc_coarse)\n",
    "    label[Test['coarse_label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_test_0.append(M)\n",
    "    X_test_1.append(p)\n",
    "    Y_test.append(label)\n",
    "\n",
    "X_test_0 = np.stack(X_test_0) \n",
    "X_test_1 = np.stack(X_test_1)  \n",
    "Y_test = np.stack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"blank = X_1\n",
    "blank_test = X_test_1\n",
    "blank = np.zeros((1960,32,43,3))\n",
    "blank_test = np.zeros((840,32,43,3))\n",
    "list = [2,3,4,5,6,5,4,3,2,7,8,9,10,9,8,7,2,1,2,11,12,13,14,13,12,11,2,15,16,17,18,17,16,15,2,19,20,21,22,21,20,19,2]\n",
    "count = 0\n",
    "for i in range(0,X_1.shape[0]):\n",
    "    for j in range(0, X_1.shape[1]):\n",
    "        count = 0\n",
    "        for k in list:\n",
    "            blank[i][j][count] = X_1[i][j][k-1]\n",
    "            count = count + 1\n",
    "count = 0\n",
    "for i in range(0, X_test_1.shape[0]):\n",
    "    for j in range(0, X_test_1.shape[1]):\n",
    "        count = 0\n",
    "        for k in list:\n",
    "            blank_test[i][j][count] = X_test_1[i][j][k-1]\n",
    "            count = count + 1\n",
    "X_1 = blank\n",
    "X_test_1 = blank_test\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training: Optimizer's Learning Rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# We use Adam to optimize a multi-class classification task\n",
    "optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training\n",
    "\n",
    "# ...with an existing validation set:\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=10, min_lr=1e-8)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "mc = ModelCheckpoint('best_model_Skel2D.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "history = model.fit(X_1, Y, validation_data=(X_test_1, Y_test), epochs=10000, batch_size=32, callbacks=[reduce_lr,es,mc])\n",
    "\n",
    "# ...or, if there is no validation set:\n",
    "# history = model.fit(x_train, y_train, validation_split=0.33, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot everything\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('best_model_Skel2D.h5')\n",
    "_, train_accuracy = model.evaluate(X_1, Y)\n",
    "_, test_accuracy = model.evaluate(X_test_1, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on train set: {:.2f}%'.format(100 * train_accuracy))\n",
    "print('Accuracy on test set: {:.2f}%'.format(100 * test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test_1)\n",
    "labels = ['Grab', 'Tap', 'Expand', 'Pinch', 'RC', 'RCC', 'SR', 'SL', 'SU', 'SD', 'SX', 'S+', 'SV', 'Shake']\n",
    "\n",
    "y_true = []\n",
    "for i in np.argmax(Y_test,axis=1):\n",
    "    y_true.append(labels[i])\n",
    "    \n",
    "y_pred = []\n",
    "for i in np.argmax(Y_pred,axis=1):\n",
    "    y_pred.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_analysis(y_true,y_pred, 'E:\\Skelnet2D\\data\\SHREC\\\\SHREC_14.png', labels, ymap=None, figsize=(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test_1)\n",
    "labels = ['Grab(1)','Grab(2)', 'Tap(1)', 'Tap(2)','Expand(1)', 'Expand(2)',\n",
    "          'Pinch(1)', 'Pinch(2)', 'RC(1)', 'RC(2)', 'RCC(1)', 'RCC(2)','SR(1)', 'SR(2)',\n",
    "          'SL(1)', 'SL(2)','SU(1)', 'SU(2)','SD(1)','SD(2)',\n",
    "           'SX(1)', 'SX(2)','S+(1)','S+(2)', 'SV(1)', 'SV(2)','Shake(1)','Shake(2)']\n",
    "\n",
    "y_true = []\n",
    "for i in np.argmax(Y_test,axis=1):\n",
    "    y_true.append(labels[i])\n",
    "    \n",
    "y_pred = []\n",
    "for i in np.argmax(Y_pred,axis=1):\n",
    "    y_pred.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_analysis(y_true,y_pred, 'E:\\Skelnet2D\\data\\SHREC\\\\SHREC_28.png', labels, ymap=None, figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
